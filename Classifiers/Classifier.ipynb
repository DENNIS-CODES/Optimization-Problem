!pip install --user numpy
!pip install --user pandas
!pip install --user matplotlib
!pip install --user seaborn
!pip install --user sklearn

import numpy as np
import pandas as pd
%matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

data_orig = pd.read_csv("../input/data-mining-assignment-2/train.csv", sep=',')#change '/..input/data-mining-assignment/train' to respective folder as downloaded
train = data_orig
data_orig = pd.read_csv("../input/data-mining-assignment-2/tested.csv", sep=',')#change '/..input/data-mining-assignment/tested' to respective folder as downloaded
test = data_orig

train.head()

test = .info()
test = data_orig
      "text/plain": [
       "Quote_Id	Quote_Date	Field_info1	Field_info2	Field_info3	Field_info4	Coverage_info1	Coverage_info2	Coverage_info3	Sales_info1	Sales_info2	Sales_info3	Sales_info4	Sales_info5	Personal_info1	Personal_info2	Personal_info3	Personal_info4	Personal_info5	Property_info1	Property_info2	Property_info3	Property_info4	Property_info5	Geographic_info1	Geographic_info2	Geographic_info3	Geographic_info4	Geographic_info5/n",
              "1	 25/1/14	     E      0.9472	       1,487	       N	       8	          22          	F              	1	        5       	7	          R	        12505	       N	           5	         ZA             	0	           2            	Y	           0        	   D	           0            	11          	9               	22              	-1                 	N               	IL/n",
              "4	 18/6/13	     F	    0.9919      	564	           N	      11	          22	        E	            0	        2          17             P     	59183	       N	           21            XR	                0   		                    N        	   0         	   R       	       1	            14	            4                   17               	-1	                N                   NJ/n",
              "5	 24/9/13	     B	    0.9403	        965	           N	       4              22	        J           	0	        3          20	          T     	61998	       N 	           25            ZA              	0	           2	            N	           0	           O	           0 	            18	            2	                11        	        -1               	N	                CA/n",
              "7   	 15/9/14	     B	    0.9153	        935	           N	      12	          22	        D      	        1	        5          11	          Q     	46142          N               19	         ZA              	0	           2              	N          	   0               D	           1	            24	            2	                12	                -1	                N         	        CA/n",
              "8   	 18/6/13	     E  	0.9485     	   1,480           N           5              22	        K	            1          	5       	1       	  P	        27464          N            	7	         ZA     	        0	           2            	N              0        	   R               0               	 4  	        9                  	23                 	-1                 	N                  	IL/n",
             "11   	 17/9/13    	 B  	0.9403      	965            N          23              22        	E           	1       	3          20         	  P     	60545          N        	    9            ZA         	    0       	   2        	    N              0               0               1               	24	            2                  	4	                -1              	N	                CA/",
             "15     8/1/14          F  	0.9838      	548            N           9              22        	E           	0          	5          20         	  T        	60030	       N	           23       	 ZN             	0       	                    N              0               R	           1            	15          	4	                16     	            -1	                N	                NJ/n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
train.duplicated().sum()


train = pd.get_dummies(train, columns=['Quote_1d','','Field_info1','Field_info2','Field_info3',Coverage_info1,Coverage_info2,Coverage_info3])

train.head()

test.info()

test.duplicated().sum()

test = pd.get_dummies(test, columns=['Field_info2','Sales_info1','Sales_info2','Sales_info3','Sales_info4','Sales_info3'])

   test.head()

#drawing correlation
 f, ax = plt.subplots(figsize=(20, 20))
corr = train.drop(columns=['ID','Class']).corr()
sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),square=True, ax=ax)

upper = corr.where(np.triu(np.ones(corr.shape), k=1).type(np.bool))
to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]

train = train.drop(train[to_drop], axis=1)

test = test.drop(test[to_drop], axis=1)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()


xtrain = train.drop(columns=['ID', 'Class'])
ytrain = train['Class']
xtest = test.drop(columns=['ID'])
xtrain = pd.DataFrame(scaler.fit_transform(xtrain))
xtest = pd.DataFrame(scaler.fit_transform(xtest))

xtest.head()

xtrain.head()
#spliting the training set into training
from sklearn.model_selection import train_test_split
X_tr, X_te, y_tr, y_te = train_test_split(xtrain, ytrain, test_size=.3,random_state=42 )

np.random.seed(42)

from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
from sklearn.model_selection import cross_validate
from sklearn.metrics import make_scorer
from sklearn.metrics import f1_score

from sklearn.ensemble import RandomForestClassifier
#te=test,tr=train randomforest search algorithm
score_train_RF = []
score_test_RF = []
#using randomForestClassifier Algorithm
for i in range(5,20,1):
    rf = RandomForestClassifier(n_estimators = 50, max_depth=i)
    rf.fit(X_tr, y_tr)
    sc_train = rf.score(X_tr,y_tr)
    score_train_RF.append(sc_train)
    sc_test = rf.score(X_te,y_te)
    score_test_RF.append(sc_test)

    plt.figure(figsize=(10,6))
train_score,=plt.plot(range(5,20,1),score_train_RF,color='red', linestyle='dashed', marker='o',
         markerfacecolor='yellow', markersize=5)
test_score,=plt.plot(range(5,20,1),score_test_RF,color='black',linestyle='dashed',  marker='o',
         markerfacecolor='blue', markersize=5)
plt.legend( [train_score,test_score],["Train Score","Test Score"])
plt.title('Fig4. Score vs. No. of Trees')
plt.xlabel('No. of Trees')
plt.ylabel('Score')


rf = RandomForestClassifier(n_estimators=100, max_depth = 6)
rf.fit(X_tr, y_tr)
rf.score(X_te,y_te)

rf = RandomForestClassifier(n_estimators=2000, max_depth = 8)
rf.fit(X_tr, y_tr)
rf.score(X_te,y_te)

y_pred_RF = rf.predict(X_te)
confusion_matrix(y_te, y_pred_RF)

print(classification_report(y_te, y_pred_RF))

from sklearn.model_selection import GridSearchCV

rf_temp = RandomForestClassifier(n_estimators = 100)        #Initialize the classifier object

parameters = {'max_depth':[6, 9],'min_samples_split':[2, 3, 4, 5]}    #Dictionary of parameters

scorer = make_scorer(f1_score, average = 'micro')         #Initialize the scorer using make_scorer

grid_obj = GridSearchCV(rf_temp, parameters, scoring=scorer)         #Initialize a GridSearchCV object with above parameters,scorer and classifier

grid_fit = grid_obj.fit(xtrain, ytrain)        #Fit the gridsearch object with X_train,y_train

best_rf = grid_fit.best_estimator_         #Get the best estimator. For this, check documentation of GridSearchCV object

print(grid_fit.best_params_)

rf_best = RandomForestClassifier(n_estimators=100, max_depth = 9, min_samples_split = 4)
rf_best.fit(X_tr, y_tr)
rf_best.score(X_te,y_te)

y_pred_RF_best = rf_best.predict(X_te)
confusion_matrix(y_te, y_pred_RF_best)

print(classification_report(y_te, y_pred_RF_best))

rf_best.fit(xtrain, ytrain)
y_test=rf_best.predict(xtest)

y_test

test['Class']=y_test
test[['ID', 'Class']].to_csv('Assignment3-Kaggle-Submission-Random-Sample.csv', index=False)

test.head()

df = pd.DataFrame(test, columns = ['ID', 'Class'])

df

#downloading test results
from IPython.display import HTML
import pandas as pd
import numpy as np
import base64
def create_download_link(df, title = "Download CSV file", filename = "data.csv"):
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode())
    payload = b64.decode()
    html = '<a download="{filename}" href="data:text/csv;base64,{payload}"target="_blank">{title}</a>'
    html = html.format(payload=payload,title=title,filename=filename)
    return HTML(html)
create_download_link(df)